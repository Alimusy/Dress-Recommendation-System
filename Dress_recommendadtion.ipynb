{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mduzXzSOOT4g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16 # Excellent for feature extraction\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO not share your API key with anyone\n",
        "API_KEY = \"8375c51346b95ef4fa94b68dfc63b436\"\n",
        "CITY_NAME = \"London\"\n",
        "UNITS = \"metric\"\n",
        "BASE_URL = \"http://api.openweathermap.org/data/2.5/weather\""
      ],
      "metadata": {
        "id": "6wgm23KMOvZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_weather_data(city, api_key, units):\n",
        "    # 1. Build the query parameters\n",
        "    params = {\n",
        "        'q': city,\n",
        "        'appid': api_key,\n",
        "        'units': units\n",
        "    }\n",
        "\n",
        "    # 2. Make the API call\n",
        "    try:\n",
        "        response = requests.get(BASE_URL, params=params)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
        "        data = response.json()\n",
        "\n",
        "        # 3. Extract the required features from the JSON response\n",
        "        weather_features = {\n",
        "            'max_temp': data['main']['temp_max'],\n",
        "            'current_temp': data['main']['temp'],\n",
        "            'feels_like': data['main']['feels_like'],\n",
        "            'description': data['weather'][0]['description'], # e.g., 'light rain'\n",
        "            'wind_speed': data['wind']['speed'],\n",
        "            'humidity': data['main']['humidity']\n",
        "        }\n",
        "\n",
        "        return weather_features\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching weather data: {e}\")\n",
        "        return None\n",
        "    except KeyError as e:\n",
        "        print(f\"Error parsing weather data (Missing key: {e}). API response structure may have changed.\")\n",
        "        return None\n",
        "\n",
        "# 4. Test the function\n",
        "weather_info = fetch_weather_data(CITY_NAME, API_KEY, UNITS)\n",
        "\n",
        "if weather_info:\n",
        "    print(f\"\\n--- Daily Weather Features For {CITY_NAME} ---\")\n",
        "    print(weather_info)\n",
        "    # Convert to a format your ML model expects (e.g., a Pandas Series)\n",
        "    weather_series = pd.Series(weather_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRUqFpfgUK5f",
        "outputId": "d909a371-925f-42d3-9dad-9cc9fb7a4bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Daily Weather Features For London ---\n",
            "{'max_temp': 16.67, 'current_temp': 15.9, 'feels_like': 15.63, 'description': 'broken clouds', 'wind_speed': 2.57, 'humidity': 80}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_weather_features(raw_data, current_date=None):\n",
        "    # Check if raw_data is not None before accessing its attributes\n",
        "    if raw_data is None:\n",
        "        return None\n",
        "\n",
        "    # Use today's date if not provided\n",
        "    if current_date is None:\n",
        "        current_date = date.today()\n",
        "\n",
        "    temp = raw_data['feels_like']\n",
        "    desc = raw_data['description']\n",
        "\n",
        "    engineered_features = {}\n",
        "\n",
        "    # --- 1. Comfort Category (Temperature & Humidity) ---\n",
        "    # Based on feels_like temp (C)\n",
        "    if temp > 30.0:\n",
        "        comfort_category = 'Hot/Humid'\n",
        "    elif 24.0 <= temp <= 30.0:\n",
        "        comfort_category = 'Warm/Mild'\n",
        "    elif 20.0 <= temp < 24.0:\n",
        "        comfort_category = 'Cool/Layering'\n",
        "    else: # Less than 20C (typical Harmattan minimums)\n",
        "        comfort_category = 'Cold/Harmattan'\n",
        "\n",
        "    engineered_features['Comfort_Category'] = comfort_category\n",
        "\n",
        "    # --- 2. Precipitation Risk ---\n",
        "    if 'heavy rain' in desc or 'thunderstorm' in desc or 'snow' in desc:\n",
        "        precipitation_risk = 2 # High Risk: Need heavy rain gear/waterproof shoes\n",
        "    elif 'rain' in desc or 'drizzle' in desc or 'shower' in desc:\n",
        "        precipitation_risk = 1 # Low Risk: Need umbrella/light jacket\n",
        "    else:\n",
        "        precipitation_risk = 0 # None\n",
        "\n",
        "    engineered_features['Precipitation_Risk'] = precipitation_risk\n",
        "\n",
        "    # --- 3. Harmattan Impact (Date-Based) ---\n",
        "    # General Harmattan window: Dec 15 - Feb 15\n",
        "    current_month = current_date.month\n",
        "    current_day = current_date.day\n",
        "\n",
        "    if (current_month == 1) or \\\n",
        "       (current_month == 12 and current_day >= 15) or \\\n",
        "       (current_month == 2 and current_day <= 15):\n",
        "        # A simple check; could be refined with humidity/wind checks\n",
        "        harmattan_impact = 2 # Peak: Need cover/long sleeves due to dust/dryness\n",
        "    elif current_month in [11, 3]: # Shoulder months\n",
        "        harmattan_impact = 1 # Layering advised\n",
        "    else:\n",
        "        harmattan_impact = 0 # None\n",
        "\n",
        "    engineered_features['Harmattan_Impact'] = harmattan_impact\n",
        "\n",
        "    # --- 4. Final Numerical/User Features (for the ML Model) ---\n",
        "    engineered_features['Feels_Like_Temp'] = temp\n",
        "    engineered_features['Humidity_Pct'] = raw_data['humidity']\n",
        "\n",
        "    # Example User Input (You'll get this from the student later)\n",
        "    engineered_features['Occasion_Formality'] = 3.0 # Example: Casual Lecture\n",
        "\n",
        "    return engineered_features\n",
        "\n",
        "# --- Running the Feature Engineering ---\n",
        "if weather_info:\n",
        "    final_features = engineer_weather_features(weather_info)\n",
        "    print(\"\\n--- Engineered Features for ML Model ---\")\n",
        "    print(final_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G90Tl9mlWiM3",
        "outputId": "0d0d9e61-2301-49b8-acef-7d3af043df3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Engineered Features for ML Model ---\n",
            "{'Comfort_Category': 'Cold/Harmattan', 'Precipitation_Risk': 0, 'Harmattan_Impact': 1, 'Feels_Like_Temp': 15.63, 'Humidity_Pct': 80, 'Occasion_Formality': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VGG16 pre-trained on ImageNet, excluding the top (classification) layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create a new model that outputs the feature vector right before the classification\n",
        "feature_extractor = Model(inputs=base_model.input,\n",
        "                          outputs=base_model.layers[-2].output)\n",
        "\n",
        "# Freeze the layers (we are using it only for extraction, not training)\n",
        "for layer in feature_extractor.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "UZkch9lOuadx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img_path):\n",
        "    # 1. Load the image and resize to VGG16 standard (224x224)\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # 2. Convert the image to a NumPy array\n",
        "    img_array = image.img_to_array(img)\n",
        "    # 3. Expand dimensions to fit model input (batch size)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # 4. Apply VGG16 specific preprocessing (scaling/centering)\n",
        "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "eeplpW8lvQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "\n",
        "# 1. Paste your original shareable URL here\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1-3MwJjgWSDZg-oEcf4PT8kEtHuXcexGeM5Y_3Xrx5xE/edit?gid=0#gid=0'\n",
        "\n",
        "# 2. Extract spreadsheet ID and gid from the URL\n",
        "match = re.search(r'/d/([a-zA-Z0-9_-]+)/edit(?:.*gid=(\\d+))?', SHEET_URL)\n",
        "\n",
        "if match:\n",
        "    spreadsheet_id = match.group(1)\n",
        "    gid = match.group(2) if match.group(2) else '0' # Default gid to 0 if not found\n",
        "    # Construct the correct export URL\n",
        "    export_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv&gid={gid}\"\n",
        "else:\n",
        "    print(\"Error: Could not parse spreadsheet ID or gid from the URL.\")\n",
        "    export_url = None # Set to None to prevent further errors\n",
        "\n",
        "if export_url:\n",
        "    # 3. Make the API call to get the CSV content\n",
        "    try:\n",
        "        response = requests.get(export_url)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
        "        csv_content = io.StringIO(response.text)\n",
        "\n",
        "        # 4. Read the data directly into a DataFrame from the CSV content\n",
        "        # Using engine='python' can sometimes help with parsing difficult files\n",
        "        wardrobe_df = pd.read_csv(csv_content, on_bad_lines='skip', engine='python')\n",
        "\n",
        "        print(\"Data loaded successfully from Google Sheet:\")\n",
        "        display(wardrobe_df.head())\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Google Sheet: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "7snCcGGH0vga",
        "outputId": "5d9a23f6-bda0-4f19-e28f-abafaad76e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully from Google Sheet:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   item_id            image_path category      sub-category  \\\n",
              "0        1             Arsen.jpg      top            jersey   \n",
              "1        2         art pants.jpg   bottom        gray pants   \n",
              "2        3     ather jackets.jpg      top      brown jacket   \n",
              "3        4       black jeans.jpg   bottom       black jeans   \n",
              "4        5  black round neck.jpg      top  black round neck   \n",
              "\n",
              "   wamrth_score (1-5)  Formality_score (1-5)  \n",
              "0                   2                      1  \n",
              "1                   3                      5  \n",
              "2                   5                      4  \n",
              "3                   3                      3  \n",
              "4                   3                      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5225791f-8b73-49b7-9d69-6e0959540cff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>category</th>\n",
              "      <th>sub-category</th>\n",
              "      <th>wamrth_score (1-5)</th>\n",
              "      <th>Formality_score (1-5)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Arsen.jpg</td>\n",
              "      <td>top</td>\n",
              "      <td>jersey</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>art pants.jpg</td>\n",
              "      <td>bottom</td>\n",
              "      <td>gray pants</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ather jackets.jpg</td>\n",
              "      <td>top</td>\n",
              "      <td>brown jacket</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>black jeans.jpg</td>\n",
              "      <td>bottom</td>\n",
              "      <td>black jeans</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>black round neck.jpg</td>\n",
              "      <td>top</td>\n",
              "      <td>black round neck</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5225791f-8b73-49b7-9d69-6e0959540cff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5225791f-8b73-49b7-9d69-6e0959540cff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5225791f-8b73-49b7-9d69-6e0959540cff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eb4cba0c-0148-4b66-8620-015c823920f1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb4cba0c-0148-4b66-8620-015c823920f1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eb4cba0c-0148-4b66-8620-015c823920f1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"        print(f\\\"An unexpected error occurred: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"art pants.jpg\",\n          \"black round neck.jpg\",\n          \"ather jackets.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"bottom\",\n          \"top\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sub-category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"gray pants\",\n          \"black round neck\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wamrth_score (1-5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Formality_score (1-5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_feature_vectors = []\n",
        "\n",
        "# Assuming your images are accessible via the Image_Path column\n",
        "for index, row in wardrobe_df.iterrows():\n",
        "    img_path = os.path.join(\"/content/drive/MyDrive/Clothing Recommendation System/Data/Images/\", row['image_path'])\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "        processed_img = preprocess_image(img_path)\n",
        "\n",
        "        # Get the feature vector (embedding)\n",
        "        features = feature_extractor.predict(processed_img)\n",
        "\n",
        "        # Flatten the vector and append it\n",
        "        all_feature_vectors.append(features.flatten())\n",
        "    else:\n",
        "        print(f\"Image not found for Item_ID {row['item_id']}\")\n",
        "        # Append a placeholder for missing images (e.g., zeros)\n",
        "        all_feature_vectors.append(np.zeros(25088)) # VGG16 feature vector size\n",
        "\n",
        "# Convert the list of vectors into a DataFrame\n",
        "feature_df = pd.DataFrame(all_feature_vectors)\n",
        "\n",
        "# Concatenate the new features with the original DataFrame\n",
        "wardrobe_df = pd.concat([wardrobe_df, feature_df], axis=1)\n",
        "\n",
        "# Save the updated DataFrame for use in Phase 3\n",
        "wardrobe_df.to_csv(\"wardrobe_inventory_features.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKTgBULvTY1",
        "outputId": "3aa6cf28-b08e-440d-d7c1-f92f21a8a6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
            "Image not found for Item_ID 5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
            "Image not found for Item_ID 10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
            "Image not found for Item_ID 13\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881ms/step\n",
            "Image not found for Item_ID 19\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
            "Image not found for Item_ID 30\n",
            "Image not found for Item_ID 31\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862ms/step\n",
            "Image not found for Item_ID 41\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
            "Image not found for Item_ID 45\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
            "Image not found for Item_ID 54\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd # Assuming you have already loaded your wardrobe_df\n",
        "\n",
        "# --- Configuration ---\n",
        "IMG_SIZE = (224, 224) # Standard input size for VGG16\n",
        "VECTOR_SIZE = 25088   # Output size of the VGG16 layer we're using\n",
        "\n",
        "# 1. Load the pre-trained VGG16 model\n",
        "#    include_top=False means we strip the final classification layer.\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "\n",
        "# 2. Create the extractor model (outputs the flattened features before classification)\n",
        "feature_extractor = Model(inputs=base_model.input,\n",
        "                          outputs=tf.keras.layers.GlobalMaxPooling2D()(base_model.output))\n",
        "                          # Using GlobalMaxPooling2D to reduce vector size (e.g., to 512 or 1024)\n",
        "                          # Use base_model.layers[-2].output for the full 25088 vector if preferred\n",
        "\n",
        "print(f\"✅ VGG16 Extractor Model loaded. Output Feature Vector Size: {feature_extractor.output_shape[1]}\")\n",
        "\n",
        "# --- Image Preprocessing Function ---\n",
        "def preprocess_image_for_vgg(img_path):\n",
        "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# --- Feature Extraction Loop ---\n",
        "all_feature_vectors = []\n",
        "\n",
        "# Define the base path for your images. This needs to match where your image files are stored.\n",
        "# Based on cell 8VKTgBULvTY1, this path was used previously.\n",
        "WARDROBE_IMAGE_BASE_PATH = \"/content/drive/MyDrive/Clothing Recommendation System/Data/Images/\"\n",
        "\n",
        "# Create the 'Full_Path' column using the 'image_path' from the DataFrame\n",
        "# This assumes 'image_path' column contains filenames that can be joined with WARDROBE_IMAGE_BASE_PATH.\n",
        "# If 'image_path' contains URLs, those would need a different handling (e.g., downloading the image first).\n",
        "wardrobe_df['Full_Path'] = wardrobe_df['image_path'].apply(lambda x: os.path.join(WARDROBE_IMAGE_BASE_PATH, x))\n",
        "\n",
        "# Use the 'Full_Path' column you created in the previous step\n",
        "for index, row in wardrobe_df.iterrows():\n",
        "    full_path = row['Full_Path']\n",
        "\n",
        "    if os.path.exists(full_path):\n",
        "        processed_img = preprocess_image_for_vgg(full_path)\n",
        "\n",
        "        # Predict the feature vector\n",
        "        features = feature_extractor.predict(processed_img, verbose=0)\n",
        "\n",
        "        all_feature_vectors.append(features.flatten())\n",
        "    else:\n",
        "        print(f\"Image not found at: {full_path}\")\n",
        "        # Append a placeholder for missing images (e.g., zeros)\n",
        "        all_feature_vectors.append(np.zeros(feature_extractor.output_shape[1]))\n",
        "\n",
        "# Convert the list of vectors into a new DataFrame\n",
        "feature_df = pd.DataFrame(all_feature_vectors, index=wardrobe_df.index)\n",
        "\n",
        "# Rename the feature columns (e.g., feature_0, feature_1, ...)\n",
        "feature_df.columns = [f'feature_{i}' for i in range(feature_df.shape[1])]\n",
        "\n",
        "# Concatenate the new features with the original DataFrame\n",
        "wardrobe_df = pd.concat([wardrobe_df, feature_df], axis=1)\n",
        "\n",
        "print(\"✅ Feature Extraction Complete.\")\n",
        "print(f\"Final DataFrame Shape: {wardrobe_df.shape}\")\n",
        "\n",
        "# Define the output path for the CSV\n",
        "output_path = \"/content/drive/MyDrive/Clothing Recommendation System/data/wardrobe_inventory_features.csv\"\n",
        "\n",
        "# Ensure the directory exists before saving\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "# Save the updated DataFrame to Drive for use in Phase 3/4\n",
        "wardrobe_df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc-hzEmp9aV1",
        "outputId": "38a3bf43-cf2a-436d-b07a-15403670cc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ VGG16 Extractor Model loaded. Output Feature Vector Size: 512\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/black round neck.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/cardgian.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/carg short.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/green round neck.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/long sleeve shirt.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/Long-sleeve sweartshirt.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/round neck short sleeve,jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/shortss.jpg\n",
            "Image not found at: /content/drive/MyDrive/Clothing Recommendation System/Data/Images/vintage pattern.jpg\n",
            "✅ Feature Extraction Complete.\n",
            "Final DataFrame Shape: (55, 100871)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Context for today (Engineered features from Phase 1)\n",
        "daily_context = {\n",
        "    'Comfort_Category': final_features['Comfort_Category'],     # 24°C - 30°C\n",
        "    'Precipitation_Risk': final_features['Precipitation_Risk'],             # Low Rain Risk\n",
        "    'Harmattan_Impact': final_features['Harmattan_Impact'],               # None\n",
        "    'Occasion_Formality_Target': final_features['Occasion_Formality'],    # E.g., Group Presentation\n",
        "    'Occasion_Warmth_Tolerance': 1     # Max warmth score tolerated for the day\n",
        "}\n",
        "\n",
        "# Define the set of item categories required for a full outfit\n",
        "OUTFIT_COMPONENTS = ['top', 'bottom', 'feet']"
      ],
      "metadata": {
        "id": "EC1xWKw5CfRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import random\n",
        "\n",
        "# Rename columns for easier access\n",
        "wardrobe_df.rename(columns={\n",
        "    'wamrth_score (1-5)': 'warmth_score',\n",
        "    'Formality_score (1-5)': 'formality_score'\n",
        "}, inplace=True)\n",
        "\n",
        "# Filter items into category lists (e.g., list of all T-shirts, list of all Jeans)\n",
        "item_pools = {cat: wardrobe_df[wardrobe_df['category'] == cat] for cat in OUTFIT_COMPONENTS}\n",
        "\n",
        "# Separate Complete Garments\n",
        "complete_garments = wardrobe_df[wardrobe_df['category'] == 'Complete_Garment']\n",
        "\n",
        "# Generate all standard outfits (Top, Bottom, Outerwear, Shoes)\n",
        "# Since Outerwear is no longer a mandatory component, we adjust the product function\n",
        "standard_combinations = list(product(item_pools['top'].itertuples(),\n",
        "                                     item_pools['bottom'].itertuples(),\n",
        "                                     item_pools['feet'].itertuples()))\n",
        "\n",
        "# Initialize the final list of scored outfits\n",
        "scored_outfits = []\n",
        "\n",
        "# --- Logic Placeholder: Compatibility Model ---\n",
        "def get_compatibility_score(outfit_items):\n",
        "    # **In a real model (Phase 3), this would run the trained MLP model**\n",
        "    # For now, assume most items are compatible (Score 0.8)\n",
        "    # The score will only be low (0.3) if a very high/low Formality_Score item is present\n",
        "    formalities = [item.formality_score for item in outfit_items]\n",
        "    if max(formalities) - min(formalities) > 3.0: # Check for huge formality mismatch\n",
        "        return 0.3 # Low score for mixing a 5 (Agbada) and a 1 (Gym shorts)\n",
        "    return 0.8\n",
        "\n",
        "\n",
        "# --- Scoring Logic ---\n",
        "for outfit_tuple in standard_combinations:\n",
        "\n",
        "    # Calculate outfit scores based on component averages\n",
        "    avg_warmth = np.mean([item.warmth_score for item in outfit_tuple])\n",
        "    avg_formality = np.mean([item.formality_score for item in outfit_tuple])\n",
        "\n",
        "    # 1. Compatibility Check (Placeholder)\n",
        "    compatibility_score = get_compatibility_score(outfit_tuple)\n",
        "\n",
        "    # 2. Appropriateness Scoring (Weather & Occasion Rules)\n",
        "\n",
        "    # Initialize penalty\n",
        "    penalty = 0\n",
        "\n",
        "    # A. Weather Warmth Penalty\n",
        "    if avg_warmth > daily_context['Occasion_Warmth_Tolerance']:\n",
        "        penalty += 0.5 * (avg_warmth - daily_context['Occasion_Warmth_Tolerance'])\n",
        "\n",
        "    # B. Rain Risk Penalty\n",
        "    # Check if any item in the current outfit is rain resistant if there's a risk\n",
        "    if daily_context['Precipitation_Risk'] > 0 and not any(getattr(item, 'Is_Rain_Resistant', False) for item in outfit_tuple):\n",
        "        penalty += 0.7 # Heavy penalty for non-waterproof shoes/outerwear in rain\n",
        "\n",
        "    # C. Formality Penalty\n",
        "    formality_mismatch = abs(avg_formality - daily_context['Occasion_Formality_Target'])\n",
        "    penalty += 1.0 * formality_mismatch # Heavy penalty for missing the formality mark\n",
        "\n",
        "    # --- Final Score Calculation ---\n",
        "    # Score is based on high compatibility, minus penalties\n",
        "    final_score = compatibility_score - penalty\n",
        "\n",
        "    scored_outfits.append({\n",
        "        'items': [item.item_id for item in outfit_tuple],\n",
        "        'score': final_score,\n",
        "        'avg_formality': avg_formality,\n",
        "        'avg_warmth': avg_warmth\n",
        "    })\n",
        "\n",
        "# --- Final Step: Rank and Recommend ---\n",
        "final_recommendations = sorted(scored_outfits, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "print(\"\\n--- TOP 3 Outfit Recommendations ---\")\n",
        "for i, rec in enumerate(final_recommendations[:3]):\n",
        "    item_names = wardrobe_df[wardrobe_df['item_id'].isin(rec['items'])]['sub-category'].tolist()\n",
        "    print(f\"#{i+1}: {', '.join(item_names)}\")\n",
        "    print(f\"   Score: {rec['score']:.2f} | Warmth: {rec['avg_warmth']:.1f} | Formality: {rec['avg_formality']:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W33uMZjeC8sl",
        "outputId": "ea60d034-c8d0-4e6c-92fd-a4031a633e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TOP 3 Outfit Recommendations ---\n",
            "#1: Man city, shorts 1, black palm 1\n",
            "   Score: 0.30 | Warmth: 2.0 | Formality: 3.0\n",
            "#2: Man city, black palm 1, black shorts\n",
            "   Score: 0.30 | Warmth: 2.0 | Formality: 3.0\n",
            "#3: shorts 1, black palm 1, white round neck\n",
            "   Score: 0.30 | Warmth: 2.0 | Formality: 3.0\n"
          ]
        }
      ]
    }
  ]
}